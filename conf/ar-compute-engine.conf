[default]

# mongo server ip location
mongo_host=192.168.0.99

# mongo server port 
mongo_port=27017

# declare the mode of ARGOeu
# can be: local or cluster
mode=cluster

# declare the serialization framework
# can be: avro or none
serialization=none

# declare if prefilter data must be cleaned after upload to hdfs
prefilter_clean=true
sync_clean=true


[logging]

# mode for logging (syslog,file,none)
log_mode=syslog

# log level status
log_level=DEBUG

# If log_mode equals file - uncomment to set log file path:
# log_file=/var/log/ar-compute/ar-compute.log

# Hadoop clients log level and log appender
# If you want to log via SYSLOG make sure
# an appropriate appender is defined in hadoop
# log4j.properties file and just add the name
# of this appender in the following line. I.e. 
# if you define a new appender named SYSLOG 
# change console to SYSLOG, or just add 
# SYSLOG appender in the following line
hadoop_log_root=INFO,console

[jobs]

tenant=EGI
job_set=Critical,Cloudmon




[sampling]

s_period=1440
s_interval=5


[datastore_mapping]

e_map=dt,ap,p,s,n,hs,a,r,up,u,d,m,pr,ss,cs,i,sc
s_map=dt,ap,p,s,n,sf,a,r,up,u,d,m,pr,ss,cs,i,sc
sd_map=ts,s,sum,msg,ps,pts,di,ti
n_eg=site
n_gg=roc
n_alt=vo
n_altf=vof
service_dest=AR.sfreports
egroup_dest=AR.sites
sdetail_dest = AR.status_metric
